{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FbOox2kGmKy9"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file=\"./ldfgnet.xmodel\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "SUf0McbmmKzC",
    "outputId": "2e42519b-e147-48f7-bf8e-14829c86d43b"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": "\ntry {\nrequire(['notebook/js/codecell'], function(codecell) {\n  codecell.CodeCell.options_default.highlight_modes[\n      'magic_text/x-csrc'] = {'reg':[/^%%microblaze/]};\n  Jupyter.notebook.events.one('kernel_ready.Kernel', function(){\n      Jupyter.notebook.get_cells().map(function(cell){\n          if (cell.cell_type == 'code'){ cell.auto_highlight(); } }) ;\n  });\n});\n} catch (e) {};\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "\ntry {\nrequire(['notebook/js/codecell'], function(codecell) {\n  codecell.CodeCell.options_default.highlight_modes[\n      'magic_text/x-csrc'] = {'reg':[/^%%pybind11/]};\n  Jupyter.notebook.events.one('kernel_ready.Kernel', function(){\n      Jupyter.notebook.get_cells().map(function(cell){\n          if (cell.cell_type == 'code'){ cell.auto_highlight(); } }) ;\n  });\n});\n} catch (e) {};\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vart::Runner@0xaaab15e83060\n"
     ]
    }
   ],
   "source": [
    "from pynq_dpu import DpuOverlay\n",
    "overlay = DpuOverlay(\"dpu.bit\")\n",
    "overlay.load_model(model_file)\n",
    "dpu = overlay.runner\n",
    "print(dpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "54ff-YmAmKzD"
   },
   "source": [
    "## 2. Utility functions\n",
    "\n",
    "In this section, we will prepare a few functions for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "lvj8cagPmKzE"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "import cv2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Power Rails Reported in PYNQ PowerBus for ZCU104#\n",
    "Reported Label\tExpected Voltage\tDescription\n",
    "12V (Main Input Power)\n",
    "INT (Internal Power Rail)\n",
    "1V8 Common auxiliary rail for FPGA and peripherals (VCCAUX, VCCO, etc.).\n",
    "1V2 Powers DDR4 memory (VCC_DDR4) and transceiver PLLs (VCC_PLL).\n",
    "MGTA Likely VCC_GTX, the power for GT transceivers.\n",
    "3V3 Supplies general I/O (VCCO for certain banks), MIO, and peripherals.\n",
    "1V13 Could be an adaptive supply for a specific FPGA block (possibly VCCINT or VCCBRAM).\n",
    "5V0\t Powers USB ports, some peripherals, and auxiliary circuits.\n",
    "FMC (default)\tVADJ_FMC, configurable voltage for the FMC connector.\n",
    "MGTRA Another GT transceiver rail, similar to MGTA.\n",
    "\n",
    "rails['12V'].power, rails['INT'].power, rails['1V8'].power, rails['1V2'].power, rails['MGTA'].power, rails['3V3'].power, \n",
    "rails['1V13'].power, rails['5V0'].power, rails['FMC'].power, rails['MGTRA'].power\n",
    "\n",
    "VCCINT (0.85V) → Most Important\n",
    "Powers the FPGA fabric, where the DPU executes computations.\n",
    "DPU inference primarily runs here, consuming most of the dynamic power.\n",
    "Power = VCCINT × Current (I_VCCINT) → Directly linked to DPU workload.\n",
    "\n",
    "12V INT (Total Board Power)\n",
    "Includes power losses in regulators and peripheral components (USB, PMIC, clocks, etc.).\n",
    "Good for estimating total board power but not precise for isolating DPU inference power.\n",
    "\n",
    "VCCINT (0.85V) → Most directly linked to DPU computations.\n",
    "✅ VCC_DDR4 (1.2V) → Significant for memory-intensive workloads.\n",
    "✅ 12V INT → Good for estimating overall board power.\n",
    "\n",
    "\n",
    "\n",
    "12V (Main Input Power)\n",
    "This is the primary 12V supply coming into the board.Powers all onboard regulators that generate lower voltages.Used to estimate total board power consumption.\n",
    "\n",
    "INT (Internal Power Rail)\n",
    "Could refer to VCCINT (0.85V), which powers the FPGA fabric.Alternatively, it might represent the total internal power consumption after conversion losses from 12V.\n",
    "If labeled separately, it might be measured after regulation (e.g., post-PMIC power delivery).\n",
    "\n",
    "Which One to Monitor for DPU Inference Power?\n",
    "If \"INT\" refers to VCCINT, then it is the best indicator of DPU power usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pynq.pmbus.DataRecorder at 0xffff59aa1870>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pynq import pmbus, DataRecorder\n",
    "rails=pmbus.get_rails()\n",
    "recorder = DataRecorder(rails['12V'].power,rails['INT'].power,rails['1V8'].power,rails['1V2'].power,rails['MGTA'].power,rails['3V3'].power,rails['1V13'].power,rails['5V0'].power,rails['FMC'].power,rails['MGTRA'].power)\n",
    "recorder.reset()\n",
    "recorder.record(0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataset(colitis, normal, polyps, esophag, pylorus, height,width):\n",
    "    imgdata=[]\n",
    "    imgclass=[]\n",
    "\n",
    "    for col, nor, pop, eso, pyl in tqdm(zip(colitis, normal,polyps, esophag, pylorus), total=len(colitis)):\n",
    "\n",
    "        img_array = cv2.imread(col,cv2.IMREAD_COLOR)\n",
    "        newim_array = cv2.cvtColor(img_array,cv2.COLOR_BGR2RGB)\n",
    "        newim_array = cv2.resize(newim_array, (height,width))  # resize to normalize data size\n",
    "        imgdata.append(newim_array)\n",
    "        clasnum=0\n",
    "        imgclass.append(clasnum)\n",
    "\n",
    "        img_array = cv2.imread(nor,cv2.IMREAD_COLOR)\n",
    "        newim_array = cv2.cvtColor(img_array,cv2.COLOR_BGR2RGB)\n",
    "        newim_array = cv2.resize(newim_array, (height,width))  # resize to normalize data size\n",
    "        imgdata.append(newim_array)\n",
    "        clasnum=1\n",
    "        imgclass.append(clasnum)\n",
    "\n",
    "        img_array = cv2.imread(pop,cv2.IMREAD_COLOR)\n",
    "        newim_array = cv2.cvtColor(img_array,cv2.COLOR_BGR2RGB)\n",
    "        newim_array = cv2.resize(newim_array, (height,width))  # resize to normalize data size\n",
    "        imgdata.append(newim_array)\n",
    "        clasnum=2\n",
    "        imgclass.append(clasnum)\n",
    "\n",
    "        img_array = cv2.imread(eso,cv2.IMREAD_COLOR)\n",
    "        newim_array = cv2.cvtColor(img_array,cv2.COLOR_BGR2RGB)\n",
    "        newim_array = cv2.resize(newim_array, (height,width))  # resize to normalize data size\n",
    "        imgdata.append(newim_array)\n",
    "        clasnum=3\n",
    "        imgclass.append(clasnum)\n",
    "\n",
    "        img_array = cv2.imread(pyl,cv2.IMREAD_COLOR)\n",
    "        newim_array = cv2.cvtColor(img_array,cv2.COLOR_BGR2RGB)\n",
    "        newim_array = cv2.resize(newim_array, (height,width))  # resize to normalize data size\n",
    "        imgdata.append(newim_array)\n",
    "        clasnum=4\n",
    "        imgclass.append(clasnum)\n",
    "\n",
    "    x_data = np.array(imgdata)\n",
    "    y_data = np.array(imgclass)\n",
    "\n",
    "\n",
    "    x_data = (x_data/255.0).astype(np.float32)\n",
    "    x_data = x_data.reshape(x_data.shape[0],height,width,3)\n",
    "  \n",
    "\n",
    "#     y_data = to_categorical(y_data, num_classes=5)    \n",
    "#     y_data = y_data.reshape(y_data.shape[0],5)\n",
    "    \n",
    "    return [x_data,y_data]\n",
    "\n",
    "\n",
    "rdstart=time.time()\n",
    "test_path = './dataset/'\n",
    "\n",
    "test_xim = sorted(glob(os.path.join(test_path, \"colitis\", \"*.jpg\")))\n",
    "test_yim = sorted(glob(os.path.join(test_path, \"normal\", \"*.jpg\")))\n",
    "test_zim = sorted(glob(os.path.join(test_path, \"polyps\", \"*.jpg\")))\n",
    "test_zaim = sorted(glob(os.path.join(test_path, \"esophag\", \"*.jpg\")))\n",
    "test_zbim = sorted(glob(os.path.join(test_path, \"pylorus\", \"*.jpg\")))\n",
    "\n",
    "#Read Dataset (train, test, valid)\n",
    "[height,width]=[128,128]\n",
    "[x_test,y_test] = read_dataset(test_xim, test_yim,test_zim, test_zaim, test_zbim, height,width)\n",
    "\n",
    "\n",
    "\n",
    "print('----------------------------------------')\n",
    "print('test shape :', x_test.shape)\n",
    "print('----------------------------------------')\n",
    "print('test label shape :', y_test.shape)\n",
    "print('----------------------------------------')\n",
    "\n",
    "images=x_test\n",
    "rdstop=time.time()\n",
    "print('The read dataset time: ',rdstop-rdstart,' sec')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "daZs6x9AmKzF"
   },
   "source": [
    "Let's first define a few useful preprocessing functions. These functions\n",
    "will make sure the DPU can take input images with arbitrary sizes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K81ykysPmKzG"
   },
   "source": [
    "We will also define a few functions to calculate softmax and provide \n",
    "the output class after running a DPU task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vR8Je46LmKzH"
   },
   "outputs": [],
   "source": [
    "def CPUCalcSoftmax(data,size):\n",
    "    sum=0.0\n",
    "    result = [0 for i in range(size)]\n",
    "    for i in range(size):\n",
    "        result[i] = math.exp(data[i])\n",
    "        sum +=result[i]\n",
    "    for i in range(size):\n",
    "        result[i] /=sum\n",
    "    return result\n",
    "\n",
    "def predict_label(softmax):\n",
    "    return np.argmax(softmax)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zpE9eDLDmKzH"
   },
   "source": [
    "Keep in mind that our original images are 640x480 so we need to preprocess them\n",
    "later to make sure it fits our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sy4NCB1jmKzI"
   },
   "source": [
    "## 3. Use VART\n",
    "Now we should be able to use VART to do image classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpu = overlay.runner\n",
    "\n",
    "inputTensors = dpu.get_input_tensors()\n",
    "outputTensors = dpu.get_output_tensors()\n",
    "\n",
    "shapeIn = tuple(inputTensors[0].dims)\n",
    "shapeOut = tuple(outputTensors[0].dims)\n",
    "outputSize = int(outputTensors[0].get_data_size() / shapeIn[0])\n",
    "\n",
    "softmax = np.empty(outputSize)\n",
    "print(shapeIn)\n",
    "print(shapeOut)\n",
    "print(outputSize)\n",
    "\n",
    "output_data = [np.empty(shapeOut, dtype=np.float32, order=\"C\")]\n",
    "input_data = [np.empty(shapeIn, dtype=np.float32, order=\"C\")]\n",
    "image = input_data[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-6IPbUVImKzI"
   },
   "source": [
    "We can define a few buffers to store input and output data. They will be reused\n",
    "during multiple runs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ys7rjuMMmKzJ"
   },
   "source": [
    "Remember that we have a list of `original_images`. \n",
    "We can now define a new function `run()` which takes the image index as \n",
    "the input, and calculate the softmax as the classification result.\n",
    "With the argument `display` set to `True`, the original image as well as the\n",
    "predicted label can be rendered.\n",
    "\n",
    "It is obvious that the range of `image_index` should be [0, `total_images`-1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "h0OPWx93mKzJ"
   },
   "outputs": [],
   "source": [
    "def run(image_index, display=False):\n",
    "    no_of_classes = 5\n",
    "    preprocessed = images[image_index]\n",
    "    \n",
    "    image[0,...] = preprocessed.reshape(\n",
    "        inputTensors[0].dims[1],\n",
    "        inputTensors[0].dims[2],\n",
    "        inputTensors[0].dims[3])\n",
    "    \n",
    "    job_id = dpu.execute_async(input_data, output_data)\n",
    "    dpu.wait(job_id)\n",
    "\n",
    "    temp = [j.reshape(1, outputSize) for j in output_data]\n",
    "    softmax = CPUCalcSoftmax(temp[0][0],no_of_classes)\n",
    "    #print(\"Classification: {}\".format(predict_label(softmax)))\n",
    "    if display:\n",
    "        display_image = images[image_index]*255\n",
    "        _, ax = plt.subplots(1)\n",
    "        _ = ax.imshow(display_image)\n",
    "        print(\"Classification: {}\".format(predict_label(softmax)))\n",
    "    return softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6osqdPFCmKzK"
   },
   "source": [
    "Let's run it for 1 image and print out the predicted label."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y63orQzzpKkN"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k8ozZEUbmKzK"
   },
   "source": [
    "We can also run it for multiple images as shown below. In this example\n",
    "we have only used 1 thread; in principle, users should be able to boost\n",
    "the performance by employing more threads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from pynq import get_rails, DataRecorder\n",
    "total =np.shape(images)[0]\n",
    "time1 = time.time()\n",
    "pred=np.array([run(i,False) for i in range(total)])\n",
    "#[val]=np.array([run(i,False) for i in range(total)])\n",
    "y_pred=pred.argmax(axis=1)\n",
    "time2 = time.time()\n",
    "fps = total/(time2-time1)\n",
    "\n",
    "print(\"Inference Time : \",time2-time1,' sec')\n",
    "print(\"Throughput Performance: {} FPS\".format(fps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results=recorder.frame\n",
    "recorder.stop()\n",
    "f_results=results.sum(axis='columns')\n",
    "\n",
    "import pandas\n",
    "f_results=results.sum(axis='columns')\n",
    "\n",
    "print('\\n')\n",
    "#print('Maximum Total Power Consumed:',max_power,'Watt' )\n",
    "print('Maximum Total Power Consumed:',f_results.max(),'Watt' )\n",
    "\n",
    "import pandas\n",
    "\n",
    "head=[]\n",
    "for col in results.columns:\n",
    "    head.append(col)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(20,8))\n",
    "plt.plot(results)\n",
    "plt.legend(head)\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Power Consumption(Watt)')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To accurately assess the Ultra96-V2 board's power consumption during DPU inference, \n",
    "it's essential to monitor the power rails supplying the Zynq UltraScale+ MPSoC, \n",
    "particularly those powering the Programmable Logic (PL) where the DPU operates. \n",
    "Among the power rails you've listed, **the VCCINT (rails['INT'].power)** is the most critical, \n",
    "as it supplies power to the internal logic of the PL. \n",
    "Monitoring this rail will provide direct insight into the power consumption of the DPU during inference tasks.\n",
    "\n",
    "While the other rails, such as VCCPSINT_FP, VCCPSINT_LP, VCCPSAUX, and VCCPSPLL, \n",
    "supply power to various domains of the Processing System (PS), \n",
    "their contribution to the overall power consumption during DPU operations is less significant compared to VCCINT. \n",
    "Therefore, focusing on the VCCINT rail will give you the most relevant data regarding the DPU's power usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print()\n",
    "# max_rail=results.max()\n",
    "# print('Maximum of all power rail =>',max_rail.idxmax(),':',max_rail.max())\n",
    "p_result=results['INT_power'].values\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(20,5))\n",
    "#plt.plot(results)\n",
    "plt.plot(p_result)\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Power Consumption(Watt)')\n",
    "print('The maximum power consumption on INT:', max(p_result),'Watt')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('---------------------------------------------------')\n",
    "print(\"Inference Time : \",time2-time1,' sec')\n",
    "print(\"Throughput Performance: {} FPS\".format(fps))\n",
    "\n",
    "print('---------------------------------------------------')\n",
    "print('Maximum Total Power Consumed:',f_results.max(),'Watt' )\n",
    "print('The maximum power consumption on VCCINT:', max(p_result),'Watt')\n",
    "print('---------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "del overlay\n",
    "del dpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Resnet_board.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
