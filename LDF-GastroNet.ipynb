{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6984dcbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.utils import shuffle\n",
    "import os\n",
    "import cv2\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4fbb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path='/model_file/ldfgnet.hdf5'\n",
    "data_dir='./dataset/kvasir5class'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0601215",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def apply_clahe(img):\n",
    "    lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n",
    "    l, a, b = cv2.split(lab)\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    l_clahe = clahe.apply(l)\n",
    "    lab_clahe = cv2.merge((l_clahe, a, b))\n",
    "    img_clahe = cv2.cvtColor(lab_clahe, cv2.COLOR_LAB2BGR)\n",
    "    return img_clahe\n",
    "\n",
    "def load_split_dataset(data_dir, img_size=(128,128), test_size=0.2, val_size=0.1, random_state=42):\n",
    "\n",
    "    class_names = sorted([d for d in os.listdir(data_dir)\n",
    "                         if os.path.isdir(os.path.join(data_dir, d))])\n",
    "\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    # Load images and preserve original labels tqdm(iterable)\n",
    "    for class_idx, class_name in enumerate(tqdm(class_names)):\n",
    "        class_path = os.path.join(data_dir, class_name)\n",
    "        for img_file in os.listdir(class_path):\n",
    "            if img_file.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp')):\n",
    "                img_path = os.path.join(class_path, img_file)\n",
    "                img = cv2.imread(img_path)\n",
    "                img = apply_clahe(img)\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                # Resize and store\n",
    "                img = cv2.resize(img, img_size)\n",
    "                images.append(img)\n",
    "                labels.append(class_idx)  # Integer label\n",
    "        time.sleep(0.05)    \n",
    "        \n",
    "    # # Convert to numpy arrays\n",
    "    x = np.array(images)\n",
    "    y = np.array(labels)\n",
    "#     y = np.expand_dims(y, axis=-1)\n",
    "\n",
    "    # # First split: separate test set\n",
    "    x_train_val, x_test, y_train_val, y_test = train_test_split(x, y, test_size=test_size, random_state=42, stratify=y)\n",
    "\n",
    "    # Second split: separate validation from training\n",
    "    val_size_adjusted = val_size / (1 - test_size)\n",
    "    x_train, x_val, y_train, y_val = train_test_split(x_train_val, y_train_val, test_size=val_size_adjusted,random_state=42, stratify=y_train_val)\n",
    "\n",
    "    # # Print summary\n",
    "    print(\"\\nData loaded successfully:\")\n",
    "    print(f\"- Total images: {len(x)}\")\n",
    "    print(f\"- Classes: {class_names}\")\n",
    "    print(f\"\\nSplit sizes:\")\n",
    "    print(f\"- Training: {len(x_train)} images\")\n",
    "    print(f\"- Validation: {len(x_val)} images\")\n",
    "    print(f\"- Test: {len(x_test)} images\")\n",
    "\n",
    "    return x_train, x_val, x_test, y_train, y_val, y_test, class_names\n",
    "\n",
    "\n",
    "img_size=(128,128)\n",
    "train_size=0.7\n",
    "test_size=0.2\n",
    "val_size=0.1\n",
    "\n",
    "# # Load and split the data (60% train, 20% val, 20% test)\n",
    "x_train, x_val, x_test, y_train, y_val, y_test, class_names = load_split_dataset(\n",
    "    data_dir,img_size=(128,128),test_size=0.2,val_size=0.1,random_state=42)\n",
    "\n",
    "np.save(\"x_test5c.npy\", x_test)\n",
    "np.save(\"y_test5c.npy\", y_test)\n",
    "print(\"\\n\")\n",
    "print(\"The test dataset saved as .npy file\")\n",
    "\n",
    "print('x_train shape ', x_train.shape)\n",
    "print('y_train shape ', y_train.shape)\n",
    "\n",
    "print('x_val shape ', x_val.shape)\n",
    "print('y_val shape ', y_val.shape)\n",
    "\n",
    "print('x_test shape ', x_test.shape)\n",
    "print('y_test shape ', y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee56e75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# performed for HyperKvasir Dataset\n",
    "#  Calculate class weights for the imbalanced dataset\n",
    "# Use the original integer labels (y_train) for this\n",
    "from sklearn.utils import class_weight\n",
    "class_weights_array = class_weight.compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(y_train),\n",
    "    y=y_train\n",
    "    \n",
    ")\n",
    "class_weights = dict(enumerate(class_weights_array))\n",
    "\n",
    "print(\"\\nCalculated Class Weights:\")\n",
    "for name, weight in zip(class_names, class_weights.values()):\n",
    "    print(f\"  - {name}: {weight:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f18b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from sklearn.utils import shuffle\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "\n",
    "# Currently Augmentation done on  Rotate, HorizontalFlip, VerticalFlip and Grayscale\n",
    "\n",
    "# !pip install albumentations==1.3.0 numpy==1.21.5 typing_extensions==4.5.0     # tf gpu 2\n",
    "\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "from albumentations import (\n",
    "    Affine,\n",
    "    HorizontalFlip,\n",
    "    VerticalFlip,\n",
    "    CenterCrop,\n",
    "    Crop,\n",
    "    Compose,\n",
    "    Transpose,\n",
    "    RandomRotate90,\n",
    "    RandomSizedCrop,\n",
    "    RandomBrightnessContrast,\n",
    "    RandomGamma,\n",
    "    HueSaturationValue,\n",
    "    RGBShift,\n",
    "    RandomBrightness,\n",
    "    RandomContrast,\n",
    "    GaussianBlur,\n",
    "    GaussNoise\n",
    "\n",
    ")\n",
    "\n",
    "def augment_data(x_train, y_train, augment=True):\n",
    "#     \"\"\" Performing data augmentation. \"\"\"\n",
    "#     crop_size = (192-32, 256-32)\n",
    "#     size = (256, 256)\n",
    "    \n",
    "    x_train_aug_list = []\n",
    "    y_train_aug_list = []\n",
    "    \n",
    "    for idx in tqdm(range(len(x_train)), desc=\"Augmenting images\"):\n",
    "        x = x_train[idx]\n",
    "        label = y_train[idx]\n",
    "\n",
    "        # ensure image is uint8 for cv2/albumentations\n",
    "        if x.dtype != np.uint8:\n",
    "            x = x.astype(np.uint8)\n",
    "\n",
    "        if augment == True:\n",
    "            ## Random Rotate 90 degree\n",
    "            aug = Affine(rotate=45, p=1)\n",
    "            augmented = aug(image=x)   \n",
    "            x1 = augmented['image']\n",
    "  \t    ## Grayscale Vertical Flip\n",
    "            aug = VerticalFlip(p=1)\n",
    "            augmented = aug(image=x)\n",
    "            x2 = augmented['image']\n",
    "\n",
    "            ## Grayscale Horizontal Flip\n",
    "            aug = HorizontalFlip(p=1)\n",
    "            augmented = aug(image=x)\n",
    "            x3 = augmented['image']\n",
    "\n",
    "            ## Transpose\n",
    "            aug = Transpose(p=1)\n",
    "            augmented = aug(image=x)\n",
    "            x4 = augmented['image']\n",
    "\n",
    "            ## Grayscale\n",
    "            x5 = cv2.cvtColor(x, cv2.COLOR_RGB2GRAY)\n",
    "            x5 = cv2.cvtColor(x5, cv2.COLOR_GRAY2RGB)\n",
    "#             print(x6.shape)\n",
    "            aug = GaussNoise(p=1)\n",
    "            augmented = aug(image=x)\n",
    "            x6 = augmented['image']\n",
    "\n",
    "            aug = RandomBrightness(p=1)\n",
    "            augmented = aug(image=x)\n",
    "            x7 = augmented['image']\n",
    "   \n",
    "            aug = RandomContrast(p=1)\n",
    "            augmented = aug(image=x)\n",
    "            x8 = augmented['image']\n",
    "\n",
    "            image = [x, x1, x2, x3, x4, x5, x6, x7, x8]\n",
    "            size = (128, 128)  # target size\n",
    "\n",
    "            rimage = [cv2.resize(img, size) for img in image]\n",
    "        else:\n",
    "            image = [x]\n",
    "            rimage = [cv2.resize(img, size) for img in image]\n",
    "            \n",
    "        x_train_aug_list.extend(rimage)  # flatten into main list\n",
    "        y_train_aug_list.extend([label]*len(rimage))  # repeat label 10 times\n",
    "   \n",
    "    x_train_aug = np.array(x_train_aug_list)\n",
    "    y_train_aug = np.array(y_train_aug_list)\n",
    "    \n",
    "    return [x_train_aug, y_train_aug]  \n",
    "\n",
    "def train_shuffling(x, y):\n",
    "    x, y = shuffle(x, y, random_state=42)\n",
    "    return x, y\n",
    "\n",
    "[x_train_aug, y_train_aug] = augment_data(x_train,y_train,augment=True)\n",
    "x_train_aug = (x_train_aug/255.0).astype(np.float32)\n",
    "\n",
    "y_train_aug = to_categorical(y_train_aug, num_classes=len(class_names))\n",
    "\n",
    "(x_train_aug, y_train_aug) = train_shuffling(x_train_aug, y_train_aug)\n",
    "print(\"finished\")\n",
    "\n",
    "x_val = (x_val/255.0).astype(np.float32)\n",
    "y_val = to_categorical(y_val, num_classes=len(class_names))\n",
    "\n",
    "x_test = x_test/255.0\n",
    "y_test = to_categorical(y_test, num_classes=len(class_names))\n",
    "\n",
    "print(\"\\nData Augumentation successfully done !:\")\n",
    "# print(f\"- Total images: {len(x)}\")\n",
    "# print(f\"- Classes: {classes}\")\n",
    "# print(f\"\\nSplit sizes:\")\n",
    "print(f\"- Training: {len(x_train)} images\")\n",
    "\n",
    "# print(x_train.shape)\n",
    "# print(y_train.shape)\n",
    "\n",
    "print('Augumented x_train shape ', x_train_aug.shape)\n",
    "print('Augumented y_train shape ', y_train_aug.shape)\n",
    "\n",
    "print('x_val shape ', x_val.shape)\n",
    "print('y_val shape ', y_val.shape)\n",
    "\n",
    "print('x_test shape ', x_test.shape)\n",
    "print('y_test shape ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9b6471",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# show first 5 augmented images\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "for i in range(10):\n",
    "    plt.subplot(1, 10, i + 1)\n",
    "    plt.imshow(x_train_aug[i])\n",
    "    plt.axis(\"off\")\n",
    "#     plt.title(f\"Label: {y_train_aug[i]}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe957ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LDFGastro-Net  ##################################\n",
    "# Code to be updated Soon !!!!\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Code to be updated soon !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d567ad85",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n Compiling the model...\")\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "    metrics=[tf.keras.metrics.CategoricalAccuracy(name=\"accuracy\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def3cc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=16\n",
    "import time\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(save_path, monitor='val_accuracy',verbose=1, save_best_only=True)\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy', factor=np.sqrt(0.1), patience=5, min_lr=0.5e-6, verbose=1)\n",
    "early_stop =  tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=15)\n",
    "callbacks = [checkpoint,reduce_lr,early_stop]\n",
    "\n",
    "trstart=time.time()\n",
    "\n",
    "history = model.fit(x_train_aug, y_train_aug, validation_data=(x_val,y_val), batch_size=batch_size, epochs=100, callbacks=callbacks, verbose=1)\n",
    "\n",
    "# history = model.fit(x_train_aug, y_train_aug, validation_data=(x_val,y_val), batch_size=batch_size, epochs=100, callbacks=callbacks, class_weight=class_weights, verbose=1)\n",
    "\n",
    "trstop=time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d699112",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "print(history.history.keys())\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Accuracy Plot')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "# plt.show()\n",
    "# summarize history for loss\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Loss Plot')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f8d0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "org_class_indices = np.argmax(y_test,axis=-1)\n",
    "print('Original Label :')\n",
    "print(org_class_indices)\n",
    "print('\\n')\n",
    "\n",
    "\n",
    "tsstart = time.time()\n",
    "pred =model.predict(x_test, verbose = 1)\n",
    "pred_class_indices = np.argmax(pred,axis=-1)\n",
    "print('Predicted Labels :')\n",
    "print(pred_class_indices)\n",
    "print('\\n')\n",
    "\n",
    "tsstop = time.time()\n",
    "print('Inference time : ', tsstop-tsstart, ' sec')\n",
    "print('\\n')\n",
    "tput=x_test.shape[0]/(tsstop-tsstart)\n",
    "print('Throughput : ',tput,' fps')\n",
    "#=======================================================================================================================================\n",
    "\n",
    "from sklearn.metrics import precision_score,recall_score,accuracy_score, f1_score\n",
    "print('Precision :  {}'.format(precision_score(y_true=org_class_indices, y_pred=pred_class_indices,average = 'macro')))\n",
    "print('Recall    :  {}'.format(recall_score(y_true=org_class_indices, y_pred=pred_class_indices,average='macro')))\n",
    "print('Accuracy  :  {}'.format(accuracy_score(y_true=org_class_indices, y_pred=pred_class_indices)))\n",
    "print('F1 Score  :  {}'.format(f1_score(y_true=org_class_indices, y_pred=pred_class_indices,average = 'macro')))\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "matrix=confusion_matrix(y_true=org_class_indices, y_pred=pred_class_indices)\n",
    "print('\\n')\n",
    "print('Confusion Matrix  : ')\n",
    "print(matrix)\n",
    "\n",
    "#========================================================================================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4595c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_path=\"./model_file/kv_denh.hdf5\"\n",
    "import tensorflow as tf\n",
    "import time\n",
    "loaded_model=tf.keras.models.load_model(best_path)\n",
    "\n",
    "org_class_indices = np.argmax(y_test,axis=-1)\n",
    "print('Original Label :')\n",
    "print(org_class_indices)\n",
    "print('\\n')\n",
    "\n",
    "\n",
    "tsstart = time.time()\n",
    "pred =model.predict(x_test, verbose = 1)\n",
    "pred_class_indices = np.argmax(pred,axis=-1)\n",
    "print('Predicted Labels :')\n",
    "print(pred_class_indices)\n",
    "print('\\n')\n",
    "\n",
    "tsstop = time.time()\n",
    "print('Inference time : ', tsstop-tsstart, ' sec')\n",
    "print('\\n')\n",
    "tput=x_test.shape[0]/(tsstop-tsstart)\n",
    "print('Throughput : ',tput,' fps')\n",
    "\n",
    "#========================================================================================================================================\n",
    "\n",
    "from sklearn.metrics import precision_score,recall_score,accuracy_score, f1_score\n",
    "print('Precision :  {}'.format(precision_score(y_true=org_class_indices, y_pred=pred_class_indices,average = 'macro')))\n",
    "print('Recall    :  {}'.format(recall_score(y_true=org_class_indices, y_pred=pred_class_indices,average='macro')))\n",
    "print('Accuracy  :  {}'.format(accuracy_score(y_true=org_class_indices, y_pred=pred_class_indices)))\n",
    "print('F1 Score  :  {}'.format(f1_score(y_true=org_class_indices, y_pred=pred_class_indices,average = 'macro')))\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "matrix=confusion_matrix(y_true=org_class_indices, y_pred=pred_class_indices)\n",
    "print('\\n')\n",
    "print('Confusion Matrix  : ')\n",
    "print(matrix)\n",
    "#========================================================================================================================================"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
